{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Optbinning` is a Python package that provides optimal binning algorithms for scorecard development and validation. A scorecard is a predictive model that assigns a score to each individual or transaction based on the probability of a certain outcome, such as default or fraud. Scorecards are widely used in the financial industry for credit scoring and fraud detection.\n",
    "\n",
    "There are several tutorials available online that show how to use optbinning to develop and monitor scorecards with different types of targets, such as binary, continuous, or multiclass. Here are some of the most relevant ones:\n",
    "\n",
    "- [Tutorial: Scorecard with binary target](^1^): This tutorial uses the dataset from the FICO Explainable Machine Learning Challenge to develop a scorecard using logistic regression as an estimator. It shows how to use the BinningProcess and Scorecard classes, as well as some plotting functions to evaluate the performance and stability of the scorecard.\n",
    "- [Tutorial: Scorecard with continuous target](^4^): This tutorial shows that scorecards are not limited to binary classification problems. It uses the California Housing dataset to develop a scorecard using Huber regression as an estimator. It also demonstrates how to reverse the scorecard direction and apply a scaling method to the scorecard points.\n",
    "- [Tutorial: Scorecard monitoring](^1^): This tutorial is a continuation of the previous two scorecard tutorials, where it focuses on scorecard monitoring. Scorecard monitoring is important to determine if the distribution of new data has shifted with respect to the original data used to develop the scorecard. It also helps to detect errors in raw data and track scorecard performance. This tutorial uses the ScorecardMonitoring class and some plotting functions to monitor the scorecard in the test dataset.\n",
    "\n",
    "I hope these tutorials are helpful for you to learn more about optbinning and scorecard development. ðŸ˜Š\n",
    "\n",
    "Source: Conversation with Bing, 2/17/2024\n",
    "(1) Tutorial: Scorecard monitoring â€” optbinning 0.19.0 documentation. http://gnpalencia.org/optbinning/tutorials/tutorial_scorecard_monitoring.html.\n",
    "(2) Tutorial: Scorecard with continuous target â€” optbinning 0.19.0 .... http://gnpalencia.org/optbinning/tutorials/tutorial_scorecard_continuous_target.html.\n",
    "(3) Tutorial: Scorecard monitoring â€” optbinning 0.19.0 documentation. http://gnpalencia.org/optbinning/tutorials/tutorial_scorecard_monitoring.html.\n",
    "(4) Tutorial: Scorecard with binary target â€” optbinning 0.19.0 documentation. http://gnpalencia.org/optbinning/tutorials/tutorial_scorecard_binary_target.html.\n",
    "(5) GitHub - GabrielSGoncalves/optbinning_tutorial. https://github.com/GabrielSGoncalves/optbinning_tutorial.\n",
    "(6) Tutorials â€” optbinning 0.19.0 documentation. http://gnpalencia.org/optbinning/tutorials.html.\n",
    "(7) undefined. https://community.fico.com/s/explainable-machine-learning-challenge.\n",
    "(8) undefined. https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it is possible to develop a scorecard with `xgboost`. Xgboost is a popular implementation of gradient boosting that can handle various types of predictive modeling problems, including classification, regression, and ranking. A scorecard is a type of classification model that assigns a score to each instance based on the probability of a certain outcome, such as default or fraud.\n",
    "\n",
    "To develop a scorecard with xgboost, you need to follow these general steps:\n",
    "\n",
    "- Prepare your data: You need to encode your categorical variables using one-hot encoding or other methods, and handle any missing values using imputation or other techniques. You also need to split your data into training and testing sets, and optionally a validation set for tuning the hyperparameters.\n",
    "- Train your xgboost model: You need to specify the objective function, the evaluation metric, and the hyperparameters for your xgboost model. You can use cross-validation, grid search, or other methods to find the optimal values for the hyperparameters. You can also use early stopping to avoid overfitting and save training time.\n",
    "- Convert your xgboost model into a scorecard: You need to map the output of your xgboost model, which is a probability or a log-odds ratio, to a score that is easy to interpret and compare. You can use a linear transformation, such as multiplying by a factor and adding an offset, or a non-linear transformation, such as applying a sigmoid function. You can also apply a scaling method to adjust the range and distribution of the scores.\n",
    "- Evaluate and monitor your scorecard: You need to assess the performance and stability of your scorecard using various metrics, such as accuracy, ROC AUC, F1-score, confusion matrix, classification report, and PSI (population stability index). You can also use plots, such as ROC curve, score distribution, and scorecard monitoring, to visualize the results.\n",
    "\n",
    "There are several online tutorials that show how to use xgboost to develop and monitor scorecards with different types of targets, such as binary, continuous, or multiclass. You can check out some of them here:\n",
    "\n",
    "- [Credit scoring using scorecardpy with XGBoost](^1^): This tutorial uses the dataset from the FICO Explainable Machine Learning Challenge to develop a scorecard using logistic regression as an estimator. It shows how to use the scorecardpy package, which is based on WOE (weight of evidence) and IV (information value), to perform binning, encoding, and scoring.\n",
    "- [Data Preparation for Gradient Boosting with XGBoost in Python](^2^): This tutorial covers some basic steps for preparing your data for using with gradient boosting with the xgboost library in Python. It shows how to encode string output variables for classification, how to prepare categorical input variables using one-hot encoding, and how to automatically handle missing data with xgboost.\n",
    "- [Credit Card Approval Model using XGBoost](^3^): This tutorial uses the German Credit dataset to develop a scorecard using xgboost as an estimator. It shows how to use the sklearn and pandas packages to perform data preprocessing, feature engineering, and model evaluation.\n",
    "- [XGBoost | credit_scorecard](^4^): This tutorial uses the Home Credit Default Risk dataset to develop a scorecard using xgboost as an estimator. It shows how to use the weights and biases package to track and compare the model performance and hyperparameters.\n",
    "-\n",
    "\n",
    "Source: Conversation with Bing, 2/17/2024\n",
    "(1) machine learning - Credit scoring using scorecardpy with XGBoost - Data .... https://datascience.stackexchange.com/questions/38817/credit-scoring-using-scorecardpy-with-xgboost.\n",
    "(2) Data Preparation for Gradient Boosting with XGBoost in Python. https://machinelearningmastery.com/data-preparation-gradient-boosting-xgboost-python/.\n",
    "(3) Credit Card Approval Model using XGBoost | Kaggle. https://www.kaggle.com/code/ramgprajapat/credit-card-approval-model-using-xgboost.\n",
    "(4) XGBoost | credit_scorecard â€“ Weights & Biases - W&B. https://wandb.ai/morgan/credit_scorecard/reports/XGBoost--VmlldzoxMjEwNzky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
